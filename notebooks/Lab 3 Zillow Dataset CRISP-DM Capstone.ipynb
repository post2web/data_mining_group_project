{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FYI directions, delete later\n",
    "\n",
    "CRISP-DM Capstone: Association Rule Mining, Clustering, or Collaborative Filtering\n",
    "\n",
    "In the final assignment for this course, you will be using one of three different analysis methods:\n",
    "\n",
    "* Option A: Use clustering on an unlabeled dataset to provide insight or features\n",
    "* Option B: Use transaction data for mining associations rules\n",
    "* Option C: Use collaborative filtering to build a custom recommendation system\n",
    "\n",
    "Your choice of dataset will largely determine the task that you are trying to achieve. Though the dataset does not need to change from your previous tasks. For example, you might choose to use clustering on your data as a preprocessing step that extracts different features. Then you can use those features to build a classifier and analyze its performance in terms of accuracy (precision, recall) and speed. Alternatively, you might choose a completely different dataset and perform rule mining or build a recommendation system.\n",
    "\n",
    "Dataset Selection and Toolkits\n",
    "\n",
    "As before, you need to choose a dataset that is not small. It might be massive in terms of the number of attributes (or transactions), classes (or items, users, etc.) or whatever is appropriate for the task you are performing. Note that scikit-learn can be used for clustering analysis, but not for Association Rule Mining (you should use R) or collaborative filtering (you should use graphlabcreate from Dato). Both can be run using Jupyter notebooks as shown in lecture.\n",
    "\n",
    "* One example of a recommendation dataset is the movie lens rating data: http://grouplens.org/\n",
    "datasets/movielens/\n",
    "* Some examples of association rule mining datasets: http://fimi.ua.ac.be/data/\n",
    "\n",
    "Write a report covering in detail all the steps of the project. The results need to be reproducible using only this report. Describe all assumptions you make and include all code you use in the Jupyter notebook or as supplemental functions. Follow the CRISP-DM framework in your analysis (you are performing all of the CRISP-DM outline). This report is worth 20% of the final grade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Zillow Dataset CRISP-DM Capstone: Association Rule Mining, Clustering, or Collaborative Filtering\n",
    "MSDS 7331 Data Mining - Section 403 - Lab 3\n",
    "\n",
    "Team: Ivelin Angelov, Yao Yao, Kaitlin Kirasich, Albert Asuncion\n",
    "\n",
    "<a id=\"top\"></a>\n",
    "## Contents\n",
    "* <a href=\"#Imports\">Imports</a>\n",
    "* <a href=\"#Business\">Business Understanding</a>\n",
    "* <a href=\"#Description\">Dataset Description</a>\n",
    "* <a href=\"#Attribute\">Attribute Visualizion</a>\n",
    "* <a href=\"#Train\">Train and Adjust Parameters</a>\n",
    "* <a href=\"#Evaluate\">Evaluate and Compare</a>\n",
    "* <a href=\"#Visualize\">Visualize Results</a>\n",
    "* <a href=\"#Ramifications\">Summarize the Ramifications</a>\n",
    "* <a href=\"#Deployment\">Deployment</a>\n",
    "* <a href=\"#Exceptional\">Exceptional Work</a>\n",
    "________________________________________________________________________________________________________\n",
    "\n",
    "<a id=\"Imports\"></a>\n",
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# load datasets here:\n",
    "train_data = pd.read_csv('../input/train_2016_v2.csv')\n",
    "data = pd.read_csv('../input/properties_2016.csv', low_memory=False)\n",
    "data = pd.merge(data, train_data, how='left', on='parcelid')\n",
    "\n",
    "'The dataset has %d rows and %d columns' % data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"Business\"></a>\n",
    "# Business Understanding\n",
    "<b>10 points</b>\n",
    "\n",
    "<i>\n",
    "<b>Description:</b><br/>\n",
    "Describe the purpose of the data set you selected (i.e., why was this data collected in the first place?). How will you measure the effectiveness of a good algorithm? Why does your chosen validation method make sense for this specific\n",
    "dataset and the stakeholders needs?\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"Description\"></a>\n",
    "# Dataset Description\n",
    "<b>10 points</b>\n",
    "\n",
    "<i>\n",
    "<b>Description:</b><br/>\n",
    "Describe the meaning and type of data (scale, values, etc.) for each attribute in the data file. Verify data quality: Are there missing values? Duplicate data? Outliers? Are those mistakes? How do you deal with these problems?\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"Attribute\"></a>\n",
    "# Attribute Visualizion\n",
    "<b>10 points</b>\n",
    "\n",
    "<i>\n",
    "<b>Description:</b><br/>\n",
    "Visualize the any important attributes appropriately. Important: Provide an interpretation for any charts or graphs.\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FYI Modeling and Evaluation, delete later\n",
    "\n",
    "Different tasks will require different evaluation methods. Be as thorough as possible when analyzing the data you have chosen and use visualizations of the results to explain the performance and expected outcomes whenever possible. Guide the reader through your analysis with plenty of discussion of the results. Each option is broken down by:\n",
    "\n",
    "* [10 Points] Train and adjust parameters\n",
    "* [10 Points] Evaluate and Compare\n",
    "* [10 Points] Visualize Results\n",
    "* [20 Points] Summarize the Ramifications\n",
    "\n",
    "Option A: Cluster Analysis\n",
    "* Train: Perform cluster analysis using several clustering methods (adjust parameters).\n",
    "* Eval: Use internal and/or external validation measures to describe and compare the clusterings and the clustersâ€” how did you determine a suitable number of clusters foreach method?\n",
    "* Visualize: Use tables/visualization to discuss the found results. Explain each visualization in detail.\n",
    "* Summarize: Describe your results. What findings are the most interesting and why?\n",
    "\n",
    "Option B: Association Rule Mining\n",
    "* Train: Create frequent itemsets and association rules (adjust parameters).\n",
    "* Eval: Use several measure for evaluating how interesting different rules are.\n",
    "* Visualize: Use tables/visualization to discuss the found results.\n",
    "* Summarize: Describe your results. What findings are the most compelling and why?\n",
    "\n",
    "Option C: Collaborative Filtering\n",
    "* Train: Create user-item matrices or item-item matrices using collaborative filtering (adjust parameters).\n",
    "* Eval: Determine performance of the recommendations using different performance measures (explain the ramifications of each measure).\n",
    "* Visualize: Use tables/visualization to discuss the found results. Explain each visualization in detail.\n",
    "* Summarize: Describe your results. What findings are the most compelling and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"Train\"></a>\n",
    "# Train and Adjust Parameters\n",
    "<b>10 points</b>\n",
    "\n",
    "<i>\n",
    "<b>Description:</b><br/>\n",
    "depends\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"Evaluate\"></a>\n",
    "# Evaluate and Compare\n",
    "<b>10 points</b>\n",
    "\n",
    "<i>\n",
    "<b>Description:</b><br/>\n",
    "depends\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"Visualize\"></a>\n",
    "# Visualize Results\n",
    "<b>10 points</b>\n",
    "\n",
    "<i>\n",
    "<b>Description:</b><br/>\n",
    "depends\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"Ramifications\"></a>\n",
    "# Summarize the Ramifications\n",
    "<b>20 points</b>\n",
    "\n",
    "<i>\n",
    "<b>Description:</b><br/>\n",
    "depends\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"Deployment\"></a>\n",
    "# Deployment\n",
    "<b>10 points</b>\n",
    "\n",
    "<i>\n",
    "<b>Description:</b><br/>\n",
    "Be critical of your performance and tell the reader how you current model might be usable by other parties. Did you achieve your goals? If not, can you reign in the utility of your modeling?\n",
    "* How useful is your model for interested parties (i.e., the companies or organizations\n",
    "that might want to use it)?\n",
    "* How would your deploy your model for interested parties?\n",
    "* What other data should be collected?\n",
    "* How often would the model need to be updated, etc.?\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "<a id=\"Exceptional\"></a>\n",
    "# Exceptional Work\n",
    "<b>10 points</b>\n",
    "\n",
    "<i>\n",
    "<b>Description:</b><br/>\n",
    "You have free reign to provide additional analyses or combine analyses.\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
