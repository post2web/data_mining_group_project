{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Mini-lab 1: Zillow Dataset Logistic Regression and SVMs  \n",
    "MSDS 7331 Data Mining - Section 403 - Mini Lab 1\n",
    "\n",
    "Team: Ivelin Angelov, Yao Yao, Kaitlin Kirasich, Albert Asuncion\n",
    "\n",
    "<a id=\"top\"></a>\n",
    "## Contents\n",
    "* <a href=\"#Imports\">Imports</a>\n",
    "* <a href=\"#Models\">Models</a>\n",
    "* <a href=\"#Advantages\">Advantages of Each Model</a>\n",
    "* <a href=\"#Feature\">Feature Importance</a>\n",
    "* <a href=\"#Insights\">Insights</a>\n",
    "________________________________________________________________________________________________________\n",
    "\n",
    "<a id=\"Imports\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "We chose to use the same Zillow dataset from Lab 1. For origin and purpose of dataset as well as a detailed description of the dataset, refer to https://github.com/post2web/data_mining_group_project/blob/master/notebooks/lab1.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-01T20:32:31.893423Z",
     "start_time": "2017-10-01T20:32:31.280059Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data, Create y and X\n",
    "We will use the Zillow dataset from our previous lab, where the cleanup files were exported from lab 1 into mini-lab 1. Note that for logistic regression and support vector classifier models, we choose to use mostly complete continuous variables as well as create dummy variables for nominal variables to cross compare the performance, feature importance, and insights of each model. X is the training set and y is the test set, where we are testing if our models can accurately predict positive logerror from that of negative logerror. \n",
    "\n",
    "Data columns that are only available for the training set and not the test set (transaction date) were removed. Parcelid was removed because each individual property has its own ID and does not correlate well with regression or SVMs. The column that was created for \"New Features\" from Lab 1 (city and pricepersqft) were also removed for the sake of simplicity of only using original data for the prediction process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-01T20:32:32.703356Z",
     "start_time": "2017-10-01T20:32:31.895175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The dataset has 116761 rows and 49 columns'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load datasets here:\n",
    "variables = pd.read_csv('../datasets/variables.csv').set_index('name')\n",
    "X = pd.read_csv('../datasets/train.csv', low_memory=False)\n",
    "\n",
    "y = (X['logerror'] > 0).astype(np.int32)\n",
    "\n",
    "del X['logerror']\n",
    "del X['transactiondate']\n",
    "del X['parcelid']\n",
    "del X['city']\n",
    "# TODO fix me\n",
    "del X['price_per_sqft']\n",
    "\n",
    "'The dataset has %d rows and %d columns' % X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Nominal Data\n",
    "Nominal data ususally has more than two values. For logistic regression and SVMs, we created dummy variables that only factor in 0s and 1s for the prediction process of logistic regression and SVMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-01T20:32:34.013315Z",
     "start_time": "2017-10-01T20:32:32.705119Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nominal = variables[variables['type'].isin(['nominal'])]\n",
    "nominal = nominal[nominal.index.isin(X.columns)]\n",
    "nominal_data = X[nominal.index]\n",
    "\n",
    "nominal_data = pd.get_dummies(nominal_data, drop_first=True)\n",
    "nominal_data = nominal_data[nominal_data.columns[~nominal_data.columns.isin(nominal.index)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Continuous Data\n",
    "StandardScaler from sklean was applied to the continuous data columns to standardize the dataset around center 0 with equal variance for creating normal distribtions prior to the application of logistic regressio and SVMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-01T20:32:34.028533Z",
     "start_time": "2017-10-01T20:32:34.015459Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "continuous = variables[~variables['type'].isin(['nominal'])]\n",
    "continuous = continuous[continuous.index.isin(X.columns)]\n",
    "\n",
    "continuous_data = X[continuous.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the data\n",
    "The data was then merged for the application of logistic regression and SVM prediction. The following shows the final shape of the dataset after the application of dummy variables and StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-01T20:32:34.121299Z",
     "start_time": "2017-10-01T20:32:34.030039Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The dataset has 116761 rows and 2107 columns'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([continuous_data, nominal_data], axis=1)\n",
    "\n",
    "columns = X.columns\n",
    "\n",
    "'The dataset has %d rows and %d columns' % X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-01T20:32:34.124699Z",
     "start_time": "2017-10-01T20:32:34.122715Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subset for test\n",
    "# X = X.iloc[:500]\n",
    "# y = y.iloc[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Models\"></a>\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "# Models\n",
    "\n",
    "<b>[50 points]</b>\n",
    "\n",
    "<i>\n",
    "Create a logistic regression model and a support vector machine model for the classification task involved with your dataset. Assess how well each model performs (use 80/20 training/testing split for your data). <b>Adjust parameters of the models to make them more accurate</b>. If your dataset size requires the use of stochastic gradient descent, then linear kernel only is fine to use. That is, the SGDClassifier is fine to use for optimizing logistic regression and linear support vector machines. For many problems, SGD will be required in order to train the SVM model in a reasonable timeframe. \n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why we use SGDClassifier?\n",
    "\n",
    "We tried out a few sklearn support vector machine functions and noticed that the accuracy was similar for each but with such a large dataset we decided to use time as our performance metric.  \n",
    "\n",
    "First first tried SVC setting kernal = 'linear' but waited a long time for it to finish.\n",
    "Next, we tried LinearSVC because the liblinear library it uses tends to be faster to converge the larger the number of samples is than the libsvm library.  \n",
    "\n",
    "Lastly, we tried and found our winner, SGDClassifier with loss = 'hinge' to use a stochastic gradient descent, which was exponentially faster than the others because it only uses a subset of the dataset. To do this we have another for loop which sets alpha and epsilon at 10 linear increments from 0.0001 to 2 and 0.00001 to .001, respectively.\n",
    "\n",
    "We found that the optimal value for alpha is 0.9 and that for epsilon is 0.00078. L1 is better than L2 for SVM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for test of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-01T20:32:34.196248Z",
     "start_time": "2017-10-01T20:32:34.126044Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_accuracy(model, n_splits=2, print_steps=False, params={}):\n",
    "    accuracies = []\n",
    "    for i in range(1, n_splits+1):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "        yhat, _ = model(\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            X_test=X_test,\n",
    "            **params\n",
    "        )\n",
    "        accuracy = float(sum(yhat==y_test)) / len(y_test)\n",
    "        accuracies.append(accuracy)\n",
    "        if print_steps:\n",
    "            matrix = pd.DataFrame(confusion_matrix(y_test, yhat),\n",
    "                columns=['Predicted 1', 'Predicted 0'],\n",
    "                index=['Actual 1', 'Actual 0'],\n",
    "            )\n",
    "            print('*' * 15 + ' Step %d ' % i + '*' * 15)\n",
    "            print('Accuracy:', accuracy)\n",
    "            print(matrix)\n",
    "            \n",
    "    return np.mean(accuracies)\n",
    "    \n",
    "def find_optimal_accuracy(model, param, param_values, params={}):\n",
    "    result = {}\n",
    "    for param_value in tqdm(list(param_values)):\n",
    "        params_local = params.copy()\n",
    "        params_local[param] = param_value\n",
    "        result[param_value] = test_accuracy(model, params=params_local)\n",
    "    \n",
    "    result = pd.Series(result).sort_index()\n",
    "    plt.xlabel(param, fontsize=15)\n",
    "    plt.ylabel('Accuracy', fontsize=15)\n",
    "    \n",
    "    optimal_param = result.argmax()\n",
    "    optimal_accuracy = result[optimal_param]\n",
    "    \n",
    "    if type(param_value) == str:\n",
    "        result.plot(kind='bar')\n",
    "    else:\n",
    "        result.plot()\n",
    "    plt.show()\n",
    "    return optimal_param\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "For the logistic regression model, we created a function that took in X_train and Y_train from the original data set to test for X_test from the modified dataset. The accuracy of the logistic regression prediction for positive or negative logerror was compared with that of the original, where a confusion matrix was made to show percentage accuracy. Due to the complexity of the dataset, we are slightly better than 50% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-01T20:32:41.727768Z",
     "start_time": "2017-10-01T20:32:34.197670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** Step 1 ***************\n",
      "Accuracy: 0.5621119342268659\n",
      "          Predicted 1  Predicted 0\n",
      "Actual 1          925         9569\n",
      "Actual 0          657        12202\n"
     ]
    }
   ],
   "source": [
    "def logistic_regression_model(X_train, y_train, X_test, **params):\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    params['loss'] = 'log'\n",
    "\n",
    "    clf = SGDClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.predict(X_test), clf\n",
    "\n",
    "best_params_logistic = {}\n",
    "\n",
    "test_accuracy(\n",
    "    model=logistic_regression_model,\n",
    "    n_splits=1, print_steps=True, params=best_params_logistic);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running logistic regression with SDGclassifier with default parameters, we got an accuracy of 0.56.  To try to improve this, we want to do a few things. \n",
    "\n",
    "First, we want to do the 80/20 split 5 times and average those results to get a better accuracy.  By splitting the training and test sets up multiple times, we can minimize the effects of outliers.\n",
    "\n",
    "Second, we want to see how changing the value of alpha and epsilon will effect the accuracy. To do this we have another for loop which sets alpha and epsilon at 10 linear increments from 0.0001 to 5 and 0.00001 to .01, respectively.\n",
    "\n",
    "We found that the optimal value for alpha is 3.3 and that for epsilon is #####. L2 is better than L1 for the logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-01T20:41:38.785829Z",
     "start_time": "2017-10-01T20:32:41.729453Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 4/4 [01:31<00:00, 22.78s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAFbCAYAAADbfIdGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDMufiIjIw7D8iYiIPMz/B90XzGC3CDAYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b60c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_iter 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 20/20 [08:10<00:00, 24.16s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfwAAAFbCAYAAAAwSzxFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4db1f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha 2.10526316368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [01:34<02:22, 23.71s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d92a9dda3e95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mparam\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mparam_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbest_params_logistic\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     )\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_params_logistic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-e0ce5890fd85>\u001b[0m in \u001b[0;36mfind_optimal_accuracy\u001b[1;34m(model, param, param_values, params)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mparams_local\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mparams_local\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparam_value\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams_local\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-e0ce5890fd85>\u001b[0m in \u001b[0;36mtest_accuracy\u001b[1;34m(model, n_splits, print_steps, params)\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mX_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         )\n\u001b[0;32m     11\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-2d36c928c107>\u001b[0m in \u001b[0;36mlogistic_regression_model\u001b[1;34m(X_train, y_train, X_test, **params)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    543\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m                          sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m         self._partial_fit(X, y, alpha, C, loss, learning_rate, self.n_iter,\n\u001b[1;32m--> 415\u001b[1;33m                           classes, sample_weight, coef_init, intercept_init)\n\u001b[0m\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, n_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m    375\u001b[0m             self._fit_binary(X, y, alpha=alpha, C=C,\n\u001b[0;32m    376\u001b[0m                              \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m                              sample_weight=sample_weight, n_iter=n_iter)\n\u001b[0m\u001b[0;32m    378\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m             raise ValueError(\"The number of class labels must be \"\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[1;34m(self, X, y, alpha, C, sample_weight, learning_rate, n_iter)\u001b[0m\n\u001b[0;32m    424\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_expanded_class_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_expanded_class_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m                                      sample_weight)\n\u001b[0m\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36mfit_binary\u001b[1;34m(est, i, X, y, alpha, C, learning_rate, n_iter, pos_weight, neg_weight, sample_weight)\u001b[0m\n\u001b[0;32m    276\u001b[0m                          \u001b[0mpos_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneg_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m                          \u001b[0mlearning_rate_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meta0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m                          est.power_t, est.t_, intercept_decay)\n\u001b[0m\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_params = dict(\n",
    "    n_iter=[1, 3, 6, 10],\n",
    "    alpha=np.linspace(0.00000001, 5, 20),\n",
    "    epsilon=np.linspace(0.00000001, .01, 10),\n",
    "    penalty=['l1', 'l2']\n",
    ")\n",
    "\n",
    "for param, param_values in test_params.items():\n",
    "    best_params_logistic[param] = find_optimal_accuracy(\n",
    "        logistic_regression_model,\n",
    "        param=param,\n",
    "        param_values=param_values,\n",
    "        params=best_params_logistic\n",
    "    )\n",
    "    print(\"Best\", param, best_params_logistic[param])\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Logistic Regression Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-01T20:42:07.021277Z",
     "start_time": "2017-10-01T20:41:38.789180Z"
    }
   },
   "outputs": [],
   "source": [
    "%%timeit -n1 -r1\n",
    "accuracy = test_accuracy(\n",
    "    logistic_regression_model, n_splits=5, params=best_params_logistic)\n",
    "print('Accuracy %f' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 VS L2 for Logistic Regression\n",
    "We further compared accuracy based on L1 or L2 penalty, where we found L2, the squared error, is slightly more accurate than L1, the error. Which is expected because typically L2 is better for minimizing error than L1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine Classifier\n",
    "For the support vector machine model, we created a function that took in X_train and Y_train from the original data set to test for X_test from the modified dataset. The accuracy of the SVM prediction for positive or negative logerror was compared with that of the original, where a confusion matrix was made to show percentage accuracy. Due to the complexity of the dataset, we are slightly better than 50% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-01T20:42:14.936373Z",
     "start_time": "2017-10-01T20:42:07.022938Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def support_vector_machine_model(X_train, y_train, X_test, **params):\n",
    "    \n",
    "    # X = (X - µ) / σ\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    params['loss'] = 'hinge'\n",
    "    clf = SGDClassifier(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.predict(X_test), clf\n",
    "\n",
    "best_params_svc = {}\n",
    "\n",
    "test_accuracy(\n",
    "    model=support_vector_machine_model,\n",
    "    n_splits=1, print_steps=True, params=best_params_svc);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running SVM with SDGclassifier with default parameters, we got an accuracy of 0.53.  To try to improve this, we want to do a few things. \n",
    "\n",
    "First, we want to do the 80/20 split 5 times and average those results to get a better accuracy.  By splitting the training and test sets up multiple times, we can minimize the effects of outliers.\n",
    "\n",
    "Second, we want to see how changing the value of alpha and epsilon will effect the accuracy. To do this we have another for loop which sets alpha and epsilon at 10 linear increments from 0.0001 to 2 and 0.00001 to .001, respectively.\n",
    "\n",
    "We found that the optimal value for alpha is 0.9 and that for epsilon is 0.00078. L2 is better than L1 for SVM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-01T21:15:47.362745Z",
     "start_time": "2017-10-01T21:08:38.770767Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_params = dict(\n",
    "    n_iter=[1, 3, 6, 10],\n",
    "    alpha=np.linspace(0.00000001, 2, 10),\n",
    "    epsilon=np.linspace(0.00000001, .001, 10),\n",
    "    penalty=['l1', 'l2']\n",
    ")\n",
    "model = support_vector_machine_model\n",
    "\n",
    "for param, test_values in test_params.items():\n",
    "    best_params_svc[param] = find_optimal_accuracy(\n",
    "        model=model,\n",
    "        param=param,\n",
    "        param_values=test_values,\n",
    "        params=best_params_svc\n",
    "    )\n",
    "    print(\"Best\", param, best_params_svc[param])\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 VS L2 for SVM\n",
    "We further compared accuracy based on L1 or L2 penalty, where we found L2, the squared error, is slightly more accurate than L1, the error. Which is expected because typically L2 is better for minimizing error than L1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Support Vector Machine Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-01T21:17:20.487064Z",
     "start_time": "2017-10-01T21:16:47.797290Z"
    }
   },
   "outputs": [],
   "source": [
    "%%timeit -n1 -r1\n",
    "accuracy = test_accuracy(\n",
    "    support_vector_machine_model, n_splits=5, params=best_params_svc)\n",
    "print('Accuracy %f' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare result ot the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-01T21:18:10.469234Z",
     "start_time": "2017-10-01T21:18:10.455655Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame([[0.528643, 28.2], [0.560134, 32.7]], columns=['Accuracy', 'Time in seconds'], index=['Logistic Regression', 'Support Vector Machine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todo seed value to make runs more constient w/ write up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Advantages\"></a>\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "## Advantages of Each Model\n",
    "<b>[10 points]</b>\n",
    "\n",
    "<i>\n",
    "Discuss the advantages of each model for each classification task. Does one type of model offer superior performance over another in terms of prediction accuracy? In terms of training time or efficiency? Explain in detail. \n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Advantages in accuracy\n",
    "\n",
    "Logistic regression runs best when there is a single linear decision boundary.  However, our dataset is a fairly hard problem to solve and the decision line is not very smooth.  We know this because we ran logistic regression one time using the built in parameters, we got an accuracy of 0.56.  After optimizing for alpha, epsilon, and L1 and L2 penalties we were only able to get a final accuracy of ####. While this was an improvement, we didn't see much payoff.  However, with logistic regression the advantage of counting on a single smooth boundary is we do not run a high risk of overfitting our model.  \n",
    "\n",
    "The advantages of support vector machines is that we can fit a region for a decision boundary, we are not constrained to a single line as above.  This is better for our dataset because we have so many factors and do not think the boundaries are a clear linear line.  This was proved when we ran SDG with basic parameters (set alpha and epsilon but did not test for optimization) and we found an accuracy of 0.53.  After optimizing, we were able to acheive an accuracy of ###.\n",
    "\n",
    "## Advantages in time and efficiency\n",
    "\n",
    "SVC with a linear kernal calculates the distance between each point in the dataset.  Thus, the run time is essentially number of features multiplied by the number of observations squared.  In other words, longer than the patience of some team members to watch it complete and is the slowest method we used.\n",
    "\n",
    "As mentioned above this was improved by LinearSVC because it is implemented using liblinear which uses a linear SVC and a logistic regression.  This means run time is log linear times linear which is better than SVC.\n",
    "\n",
    "Logistic regression uses the liblinear library and uses a one vs the rest algorithm.  This means that the run time is in log linear time, improving the efficiency from SVC functions.\n",
    "\n",
    "SGDClassifier is fastest and arguably linear, which to a software engineer a matrix can only run in n * m for n the number of features and m the number of observations.   It's convergence to a solution depending on the loss setting means it uses only a subset of the dataset also improving time. This is why we used SGDClassifier for both logistic regression and SVM\n",
    "\n",
    "In terms of our dataset, we have about 2000 features which is a sparse dataset.  Logistic regression turned out to be the fastest but SDGClassifier is a close second.  \n",
    "\n",
    "## Conclusion\n",
    "\n",
    "SDG was our best performer in terms of accuracy (0.57) and logistic regression was our fastest (2000ms).  We felt that the larger magnitude of how much better the accuracy was versus the smaller magnitude of how much slower SDG was to logistic regression that SDG is our best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Feature\"></a>\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "## Feature Importance\n",
    "<b>[30 points]</b>\n",
    "    \n",
    "<i>\n",
    "Use the weights from logistic regression to interpret the importance of different features for the classification task. Explain your interpretation in detail. Why do you think some variables are more important?\n",
    "</i>\n",
    "\n",
    "# Logistic Regression Feature Importance\n",
    "\n",
    "After scaling the continuous variables, the feature importance showed that propertyzoningdesc and propertycountylandusecode for multiple counties showed the most importance for predicting logerror. This might be due to the fact that neighborhoods based on location highly dictate the sales price of a property. Tax was also a big factor. Perhaps the more land owners pay for property tax could better predict property value because more amenities could be added for a richer neighborhood than that for a poorer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-01T20:58:42.461486Z",
     "start_time": "2017-10-01T20:32:31.304Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, clf = logistic_regression_model(X_train=X, y_train=y, X_test=X, **best_params_logistic)\n",
    "\n",
    "abs_coefs = np.abs(clf.coef_[0])\n",
    "top_50_vars = pd.Series(abs_coefs, index=X.columns).sort_values().index[:50]\n",
    "\n",
    "importance_top_50 = pd.Series(clf.coef_[0], index=X.columns).loc[top_50_vars]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 20))\n",
    "importance_top_50.plot(kind='barh', ax=ax)\n",
    "plt.title('Logistic Regression Feature Importance (TOP 50 Variables)')\n",
    "plt.xlabel('Weight', fontsize=15)\n",
    "plt.ylabel('Feature', fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Insights\"></a>\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "## Insights\n",
    "<b>[10 points]</b>\n",
    "\n",
    "<i>\n",
    "Look at the chosen support vectors for the classification task. Do these provide any insight into the data? Explain. If you used stochastic gradient descent (and therefore did not explicitly solve for support vectors), try subsampling your data to train the SVC model — then analyze the support vectors from the subsampled dataset. \n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret support vectors\n",
    "\n",
    "# TODO: Review KDE results. The expected result is for the logerrors to be closer together in the support vectors and further apart in the original. These results are the other way around. \n",
    "\n",
    "# TODO: remake cells 32 and 33 from https://github.com/eclarson/DataMiningNotebooks/blob/master/04.%20Logits%20and%20SVM.ipynb for us to write about it\n",
    "\n",
    "Using Kernel Density Estimation we reviewed support vectors for logerror equals 0 versus 1 for a number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-01T20:58:42.462222Z",
     "start_time": "2017-10-01T20:32:31.309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nubmer of support vectros for each feature: [18 20]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='linear', max_iter=20)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "clf.fit(X_scaled, y)\n",
    "\n",
    "# this hold the indexes of the support vectors\n",
    "clf.support_\n",
    "\n",
    "# this holds a subset of the data which is used for support vectors\n",
    "clf.support_vectors_\n",
    "support_vectors = pd.DataFrame(clf.support_vectors_, columns=X.columns)\n",
    "\n",
    "# get number of support vectors for each class\n",
    "print('Nubmer of support vectros for each feature:', clf.n_support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13411,  13626,  21059,  21772,  26236,  26833,  40576,  44724,\n",
       "        51759,  53551,  61271,  61826,  63788,  73168,  75611,  99591,\n",
       "       113150, 116759,  25605,  26832,  37700,  37769,  41174,  42821,\n",
       "        50118,  50656,  50671,  54047,  61298,  65992,  83750,  91944,\n",
       "        92005,  93032,  96209,  98395, 110135, 110834])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.support_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'logerror'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2392\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2393\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2394\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5239)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5085)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20405)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20359)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'logerror'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a9493d70d58d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Add logerror back in to X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0msupport_vectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'logerror'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'logerror'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2060\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2062\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2063\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2064\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2067\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2068\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2069\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2071\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1532\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1533\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1534\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1535\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3589\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3590\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3591\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2393\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2394\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2395\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2397\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5239)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5085)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20405)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20359)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'logerror'"
     ]
    }
   ],
   "source": [
    "# Add logerror column to the dataframe\n",
    "support_vectors['logerror'] = y[clf.support_]\n",
    "\n",
    "# Add logerror back in to X\n",
    "support_vectors['logerror'] = X['logerror']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import boxplot\n",
    "\n",
    "# group the original data and the support vectors\n",
    "support_vectors_grouped = support_vectors.groupby(['logerror'])\n",
    "X_grouped = X.groupby(['logerror'])\n",
    "\n",
    "# plot KDE of Different variables\n",
    "vars_to_plot = ['bathroomcnt','fullbathcnt','taxamount','taxvaluedollarcnt',\n",
    "                'calculatedbathnbr','yearbuilt']\n",
    "\n",
    "for v in vars_to_plot:\n",
    "    plt.figure(figsize=(10,4))\n",
    "    # plot support vector stats\n",
    "    plt.subplot(1,2,1)\n",
    "    ax = support_vectors_grouped[v].plot.kde() \n",
    "    plt.legend(['logerror 0','logerror 1'])\n",
    "    plt.title(v+' (Instances chosen as Support Vectors)')\n",
    "    \n",
    "    # plot original distributions\n",
    "    plt.subplot(1,2,2)\n",
    "    ax = X_grouped[v].plot.kde() \n",
    "    plt.legend(['logerror 0','logerror 1'])\n",
    "    plt.title(v+' (Original)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Back to Top</a>\n",
    "# References:\n",
    "\n",
    "- Kernels from Kaggle competition: https://www.kaggle.com/c/zillow-prize-1/kernels\n",
    "- Scikitlearn logistic regression: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "- Scikitlearn linear SVC: http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\n",
    "- Stackoverflow pandas questions: https://stackoverflow.com/questions/tagged/pandas\n",
    "- Scikitlearn SDGClassfier: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "426px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
