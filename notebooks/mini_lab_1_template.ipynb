{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Mini-lab 1\n",
    "MSDS 7331 Data Mining - Section 403 - Mini Lab 1\n",
    "\n",
    "Team: Ivelin Angelov, Yao Yao, Kaitlin Kirasich, Albert Asuncion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/__init__.py:878: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data, crate y and X\n",
    "We will use the Zillow dataset from our previous lab 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The dataset has 116761 rows and 50 columns'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load datasets here:\n",
    "variables = pd.read_csv('../datasets/variables.csv').set_index('name')\n",
    "X = pd.read_csv('../datasets/train.csv', low_memory=False)\n",
    "\n",
    "y = (X['logerror'] > 0).astype(np.int32)\n",
    "\n",
    "del X['logerror']\n",
    "del X['transactiondate']\n",
    "del X['parcelid']\n",
    "# TODO fix me\n",
    "del X['price_per_sqft']\n",
    "\n",
    "'The dataset has %d rows and %d columns' % X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: fix me\n",
    "\n",
    "for now we just use continuous vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = variables[~variables['type'].isin(['nominal'])]\n",
    "continuous = continuous[continuous.index.isin(X.columns)]\n",
    "\n",
    "X = X[continuous.index]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# X = (X - µ) / σ\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>[50 points]</b>\n",
    "<i>\n",
    "Create a logistic regression model and a support vector machine model for the classification task involved with your dataset. Assess how well each model performs (use 80/20 training/testing split for your data). <b>Adjust parameters of the models to make them more accurate</b>. If your dataset size requires the use of stochastic gradient descent, then linear kernel only is fine to use. That is, the SGDClassifier is fine to use for optimizing logistic regression and linear support vector machines. For many problems, SGD will be required in order to train the SVM model in a reasonable timeframe. \n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Percentage accuracy:', 0.5639554303234813)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 1</th>\n",
       "      <th>Predicted 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>10388</td>\n",
       "      <td>41930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>8983</td>\n",
       "      <td>55460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 1  Predicted 0\n",
       "Actual 1        10388        41930\n",
       "Actual 0         8983        55460"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, y)\n",
    "yhat = clf.predict(X)\n",
    "\n",
    "accuracy = float(sum(yhat==y)) / len(y)\n",
    "print('Percentage accuracy:', accuracy)\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y, yhat),\n",
    "    columns=['Predicted 1', 'Predicted 0'], \n",
    "    index=['Actual 1', 'Actual 0'], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Percentage accuracy:', 0.5639639948270398)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 1</th>\n",
       "      <th>Predicted 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>10063</td>\n",
       "      <td>42255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>8657</td>\n",
       "      <td>55786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 1  Predicted 0\n",
       "Actual 1        10063        42255\n",
       "Actual 0         8657        55786"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "\n",
    "#clf = SVC(kernel='linear')\n",
    "clf = LinearSVC(max_iter=1000)\n",
    "clf.fit(X, y)\n",
    "yhat = clf.predict(X)\n",
    "\n",
    "accuracy = float(sum(yhat==y)) / len(y)\n",
    "print('Percentage accuracy:', accuracy)\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y, yhat),\n",
    "    columns=['Predicted 1', 'Predicted 0'], \n",
    "    index=['Actual 1', 'Actual 0'], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance\n",
    "<i>\n",
    "Assess how well each model performs (use 80/20 training/testing split for your data). Adjust parameters of the models to make them more accurate. If your dataset size requires the use of stochastic gradient descent, then linear kernel only is fine to use. That is, the SGDClassifier is fine to use for optimizing logistic regression and linear support vector machines. For many problems, SGD will be required in order to train the SVM model in a reasonable timeframe.\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Percentage accuracy:', 0.5648524814798955)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 1</th>\n",
       "      <th>Predicted 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>2136</td>\n",
       "      <td>8251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>1911</td>\n",
       "      <td>11055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 1  Predicted 0\n",
       "Actual 1         2136         8251\n",
       "Actual 0         1911        11055"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "yhat = clf.predict(X_test)\n",
    "\n",
    "accuracy = float(sum(yhat==y_test)) / len(y_test)\n",
    "print('Percentage accuracy:', accuracy)\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, yhat),\n",
    "    columns=['Predicted 1', 'Predicted 0'], \n",
    "    index=['Actual 1', 'Actual 0'], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages of each model\n",
    "<b>[10 points]</b>\n",
    "\n",
    "<i>\n",
    "Discuss the advantages of each model for each classification task. Does one type of model offer superior performance over another in terms of prediction accuracy? In terms of training time or efficiency? Explain in detail. \n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "<b>[30 points]</b>\n",
    "    \n",
    "<i>\n",
    "Use the weights from logistic regression to interpret the importance of different features for the classification task. Explain your interpretation in detail. Why do you think some variables are more important?\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights\n",
    "<b>[10 points]</b>\n",
    "\n",
    "<i>\n",
    "Look at the chosen support vectors for the classification task. Do these provide any insight into the data? Explain. If you used stochastic gradient descent (and therefore did not explicitly solve for support vectors), try subsampling your data to train the SVC model — then analyze the support vectors from the subsampled dataset. \n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code for any sub sampling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
